[Epoch 1 | Batch 000 | Step 00] Loss_cls = 2.3819, Loss_grad = 62.0000, L2 = 0.3313, Dot = 0.1183, Cosine = 1.0000
[Epoch 1 | Batch 000 | Step 01] Loss_cls = 2.5727, Loss_grad = 61.0969, L2 = 0.5219, Dot = 0.6502, Cosine = 0.9854
[Epoch 1 | Batch 000 | Step 02] Loss_cls = 2.9592, Loss_grad = 49.0071, L2 = 0.3941, Dot = 0.2473, Cosine = 0.7904
[Epoch 1 | Batch 000 | Step 03] Loss_cls = 3.3564, Loss_grad = 46.8586, L2 = 0.5198, Dot = 0.6012, Cosine = 0.7558
[Epoch 1 | Batch 000 | Step 04] Loss_cls = 2.8406, Loss_grad = 48.6747, L2 = 0.4197, Dot = 0.2537, Cosine = 0.7851
[Epoch 1 | Batch 001 | Step 00] Loss_cls = 2.8613, Loss_grad = 62.0000, L2 = 0.4993, Dot = 0.3143, Cosine = 1.0000
[Epoch 1 | Batch 001 | Step 01] Loss_cls = 3.0164, Loss_grad = 61.7615, L2 = 0.6701, Dot = 1.0896, Cosine = 0.9962
[Epoch 1 | Batch 001 | Step 02] Loss_cls = 2.6961, Loss_grad = 59.0456, L2 = 0.3981, Dot = 0.1469, Cosine = 0.9523
[Epoch 1 | Batch 001 | Step 03] Loss_cls = 3.2464, Loss_grad = 59.4651, L2 = 0.5305, Dot = 0.2669, Cosine = 0.9591
[Epoch 1 | Batch 001 | Step 04] Loss_cls = 3.0888, Loss_grad = 60.6295, L2 = 0.5958, Dot = 0.2831, Cosine = 0.9779
[Epoch 1 | Batch 002 | Step 00] Loss_cls = 2.8056, Loss_grad = 62.0000, L2 = 0.3148, Dot = 0.1057, Cosine = 1.0000
[Epoch 1 | Batch 002 | Step 01] Loss_cls = 2.4991, Loss_grad = 61.9695, L2 = 0.2952, Dot = 0.0825, Cosine = 0.9995
[Epoch 1 | Batch 002 | Step 02] Loss_cls = 2.2225, Loss_grad = 59.8896, L2 = 0.2112, Dot = 0.0332, Cosine = 0.9660
[Epoch 1 | Batch 002 | Step 03] Loss_cls = 2.1117, Loss_grad = 54.7528, L2 = 0.1854, Dot = 0.0251, Cosine = 0.8831
[Epoch 1 | Batch 002 | Step 04] Loss_cls = 2.0642, Loss_grad = 55.9470, L2 = 0.3812, Dot = 0.1539, Cosine = 0.9024
[Epoch 1 | Batch 003 | Step 00] Loss_cls = 2.0448, Loss_grad = 62.0000, L2 = 0.1973, Dot = 0.0293, Cosine = 1.0000
[Epoch 1 | Batch 003 | Step 01] Loss_cls = 1.9164, Loss_grad = 61.9188, L2 = 0.1414, Dot = 0.0153, Cosine = 0.9987
[Epoch 1 | Batch 003 | Step 02] Loss_cls = 1.8193, Loss_grad = 57.0224, L2 = 0.1735, Dot = 0.0216, Cosine = 0.9197
[Epoch 1 | Batch 003 | Step 03] Loss_cls = 1.7448, Loss_grad = 34.9305, L2 = 0.1492, Dot = 0.0153, Cosine = 0.5634
[Epoch 1 | Batch 003 | Step 04] Loss_cls = 1.6621, Loss_grad = 19.7930, L2 = 0.1533, Dot = 0.0098, Cosine = 0.3192
[Epoch 1 | Batch 004 | Step 00] Loss_cls = 1.9427, Loss_grad = 62.0000, L2 = 0.3014, Dot = 0.0636, Cosine = 1.0000
[Epoch 1 | Batch 004 | Step 01] Loss_cls = 1.7876, Loss_grad = 61.9778, L2 = 0.1560, Dot = 0.0185, Cosine = 0.9996
[Epoch 1 | Batch 004 | Step 02] Loss_cls = 1.7857, Loss_grad = 52.1404, L2 = 0.1619, Dot = 0.0164, Cosine = 0.8410
[Epoch 1 | Batch 004 | Step 03] Loss_cls = 1.7506, Loss_grad = 39.4208, L2 = 0.1596, Dot = 0.0143, Cosine = 0.6358
[Epoch 1 | Batch 004 | Step 04] Loss_cls = 1.6878, Loss_grad = 21.6035, L2 = 0.1476, Dot = 0.0105, Cosine = 0.3484
[Epoch 1 | Batch 005 | Step 00] Loss_cls = 1.9048, Loss_grad = 62.0000, L2 = 0.2321, Dot = 0.0384, Cosine = 1.0000
[Epoch 1 | Batch 005 | Step 01] Loss_cls = 1.7987, Loss_grad = 61.9866, L2 = 0.1668, Dot = 0.0192, Cosine = 0.9998
[Epoch 1 | Batch 005 | Step 02] Loss_cls = 1.8171, Loss_grad = 53.7128, L2 = 0.1783, Dot = 0.0189, Cosine = 0.8663
[Epoch 1 | Batch 005 | Step 03] Loss_cls = 1.7513, Loss_grad = 37.2731, L2 = 0.1466, Dot = 0.0137, Cosine = 0.6012
[Epoch 1 | Batch 005 | Step 04] Loss_cls = 1.6612, Loss_grad = 19.1612, L2 = 0.1136, Dot = 0.0076, Cosine = 0.3091
[Epoch 1 | Batch 006 | Step 00] Loss_cls = 1.7886, Loss_grad = 62.0000, L2 = 0.1921, Dot = 0.0257, Cosine = 1.0000
[Epoch 1 | Batch 006 | Step 01] Loss_cls = 1.7418, Loss_grad = 61.9874, L2 = 0.1495, Dot = 0.0141, Cosine = 0.9998
[Epoch 1 | Batch 006 | Step 02] Loss_cls = 1.7845, Loss_grad = 46.2064, L2 = 0.1204, Dot = 0.0089, Cosine = 0.7453
[Epoch 1 | Batch 006 | Step 03] Loss_cls = 1.8016, Loss_grad = 26.1539, L2 = 0.1089, Dot = 0.0075, Cosine = 0.4218
[Epoch 1 | Batch 006 | Step 04] Loss_cls = 1.8103, Loss_grad = 21.1051, L2 = 0.1080, Dot = 0.0066, Cosine = 0.3404
[Epoch 1 | Batch 007 | Step 00] Loss_cls = 1.8304, Loss_grad = 62.0000, L2 = 0.1980, Dot = 0.0270, Cosine = 1.0000
[Epoch 1 | Batch 007 | Step 01] Loss_cls = 1.7475, Loss_grad = 61.9945, L2 = 0.1484, Dot = 0.0147, Cosine = 0.9999
[Epoch 1 | Batch 007 | Step 02] Loss_cls = 1.7506, Loss_grad = 57.1194, L2 = 0.1440, Dot = 0.0176, Cosine = 0.9213
[Epoch 1 | Batch 007 | Step 03] Loss_cls = 1.7410, Loss_grad = 38.2294, L2 = 0.1113, Dot = 0.0074, Cosine = 0.6166
[Epoch 1 | Batch 007 | Step 04] Loss_cls = 1.7493, Loss_grad = 35.9585, L2 = 0.1480, Dot = 0.0133, Cosine = 0.5800
[Epoch 1 | Batch 008 | Step 00] Loss_cls = 1.7793, Loss_grad = 62.0000, L2 = 0.2016, Dot = 0.0286, Cosine = 1.0000
[Epoch 1 | Batch 008 | Step 01] Loss_cls = 1.6993, Loss_grad = 61.9963, L2 = 0.1566, Dot = 0.0174, Cosine = 0.9999
[Epoch 1 | Batch 008 | Step 02] Loss_cls = 1.6336, Loss_grad = 57.1300, L2 = 0.1094, Dot = 0.0084, Cosine = 0.9215
[Epoch 1 | Batch 008 | Step 03] Loss_cls = 1.6338, Loss_grad = 50.0373, L2 = 0.1234, Dot = 0.0108, Cosine = 0.8071
[Epoch 1 | Batch 008 | Step 04] Loss_cls = 1.6403, Loss_grad = 39.7260, L2 = 0.1343, Dot = 0.0119, Cosine = 0.6407
[Epoch 1 | Batch 009 | Step 00] Loss_cls = 1.7514, Loss_grad = 62.0000, L2 = 0.1346, Dot = 0.0158, Cosine = 1.0000
[Epoch 1 | Batch 009 | Step 01] Loss_cls = 1.7106, Loss_grad = 61.9740, L2 = 0.1167, Dot = 0.0101, Cosine = 0.9996
[Epoch 1 | Batch 009 | Step 02] Loss_cls = 1.7134, Loss_grad = 52.8886, L2 = 0.1241, Dot = 0.0119, Cosine = 0.8530
[Epoch 1 | Batch 009 | Step 03] Loss_cls = 1.7069, Loss_grad = 33.6596, L2 = 0.1122, Dot = 0.0081, Cosine = 0.5429
[Epoch 1 | Batch 009 | Step 04] Loss_cls = 1.6865, Loss_grad = 0.6927, L2 = 0.0900, Dot = 0.0017, Cosine = 0.0112
[Epoch 1 | Batch 010 | Step 00] Loss_cls = 1.7136, Loss_grad = 62.0000, L2 = 0.1803, Dot = 0.0251, Cosine = 1.0000
[Epoch 1 | Batch 010 | Step 01] Loss_cls = 1.6661, Loss_grad = 61.9936, L2 = 0.1376, Dot = 0.0117, Cosine = 0.9999
[Epoch 1 | Batch 010 | Step 02] Loss_cls = 1.6080, Loss_grad = 55.8156, L2 = 0.1327, Dot = 0.0121, Cosine = 0.9003
[Epoch 1 | Batch 010 | Step 03] Loss_cls = 1.5539, Loss_grad = 34.3393, L2 = 0.1067, Dot = 0.0073, Cosine = 0.5539
[Epoch 1 | Batch 010 | Step 04] Loss_cls = 1.5122, Loss_grad = 2.7985, L2 = 0.1003, Dot = 0.0047, Cosine = 0.0451
[Epoch 1 | Batch 011 | Step 00] Loss_cls = 1.7247, Loss_grad = 62.0000, L2 = 0.2522, Dot = 0.0528, Cosine = 1.0000
[Epoch 1 | Batch 011 | Step 01] Loss_cls = 1.6047, Loss_grad = 61.9945, L2 = 0.1807, Dot = 0.0219, Cosine = 0.9999
[Epoch 1 | Batch 011 | Step 02] Loss_cls = 1.6109, Loss_grad = 55.7060, L2 = 0.1674, Dot = 0.0195, Cosine = 0.8985
[Epoch 1 | Batch 011 | Step 03] Loss_cls = 1.5895, Loss_grad = 33.4420, L2 = 0.1374, Dot = 0.0132, Cosine = 0.5394
[Epoch 1 | Batch 011 | Step 04] Loss_cls = 1.5575, Loss_grad = 16.8485, L2 = 0.1083, Dot = 0.0041, Cosine = 0.2717
[Epoch 1 | Batch 012 | Step 00] Loss_cls = 1.6922, Loss_grad = 62.0000, L2 = 0.1810, Dot = 0.0232, Cosine = 1.0000
[Epoch 1 | Batch 012 | Step 01] Loss_cls = 1.6630, Loss_grad = 61.9952, L2 = 0.1612, Dot = 0.0178, Cosine = 0.9999
[Epoch 1 | Batch 012 | Step 02] Loss_cls = 1.5358, Loss_grad = 55.0235, L2 = 0.1156, Dot = 0.0085, Cosine = 0.8875
[Epoch 1 | Batch 012 | Step 03] Loss_cls = 1.4868, Loss_grad = 50.7125, L2 = 0.1089, Dot = 0.0076, Cosine = 0.8179
[Epoch 1 | Batch 012 | Step 04] Loss_cls = 1.4508, Loss_grad = 39.5423, L2 = 0.1112, Dot = 0.0068, Cosine = 0.6378
[Epoch 1 | Batch 013 | Step 00] Loss_cls = 1.5503, Loss_grad = 62.0000, L2 = 0.1331, Dot = 0.0130, Cosine = 1.0000
[Epoch 1 | Batch 013 | Step 01] Loss_cls = 1.4984, Loss_grad = 61.9899, L2 = 0.1172, Dot = 0.0087, Cosine = 0.9998
[Epoch 1 | Batch 013 | Step 02] Loss_cls = 1.5034, Loss_grad = 47.9460, L2 = 0.0943, Dot = 0.0053, Cosine = 0.7733
[Epoch 1 | Batch 013 | Step 03] Loss_cls = 1.5378, Loss_grad = 24.4960, L2 = 0.1196, Dot = 0.0090, Cosine = 0.3951
[Epoch 1 | Batch 013 | Step 04] Loss_cls = 1.5083, Loss_grad = 7.3226, L2 = 0.1226, Dot = 0.0051, Cosine = 0.1181
[Epoch 1 | Batch 014 | Step 00] Loss_cls = 1.8023, Loss_grad = 62.0000, L2 = 0.3170, Dot = 0.0649, Cosine = 1.0000
[Epoch 1 | Batch 014 | Step 01] Loss_cls = 1.6369, Loss_grad = 61.9975, L2 = 0.1956, Dot = 0.0239, Cosine = 1.0000
[Epoch 1 | Batch 014 | Step 02] Loss_cls = 1.5414, Loss_grad = 53.8963, L2 = 0.1424, Dot = 0.0181, Cosine = 0.8693
[Epoch 1 | Batch 014 | Step 03] Loss_cls = 1.5170, Loss_grad = 44.5851, L2 = 0.1526, Dot = 0.0194, Cosine = 0.7191
[Epoch 1 | Batch 014 | Step 04] Loss_cls = 1.4590, Loss_grad = 30.4103, L2 = 0.1406, Dot = 0.0119, Cosine = 0.4905
[Epoch 1 | Batch 015 | Step 00] Loss_cls = 1.7241, Loss_grad = 62.0000, L2 = 0.2044, Dot = 0.0261, Cosine = 1.0000
[Epoch 1 | Batch 015 | Step 01] Loss_cls = 1.6487, Loss_grad = 61.9964, L2 = 0.1359, Dot = 0.0124, Cosine = 0.9999
[Epoch 1 | Batch 015 | Step 02] Loss_cls = 1.5885, Loss_grad = 52.9499, L2 = 0.1305, Dot = 0.0136, Cosine = 0.8540
[Epoch 1 | Batch 015 | Step 03] Loss_cls = 1.5348, Loss_grad = 44.6601, L2 = 0.1521, Dot = 0.0164, Cosine = 0.7203
[Epoch 1 | Batch 015 | Step 04] Loss_cls = 1.4364, Loss_grad = 29.5859, L2 = 0.1362, Dot = 0.0100, Cosine = 0.4772
[Epoch 1 | Batch 016 | Step 00] Loss_cls = 1.7406, Loss_grad = 62.0000, L2 = 0.2518, Dot = 0.0459, Cosine = 1.0000
[Epoch 1 | Batch 016 | Step 01] Loss_cls = 1.5965, Loss_grad = 61.9876, L2 = 0.1656, Dot = 0.0179, Cosine = 0.9998
[Epoch 1 | Batch 016 | Step 02] Loss_cls = 1.6007, Loss_grad = 50.8155, L2 = 0.1605, Dot = 0.0215, Cosine = 0.8196
[Epoch 1 | Batch 016 | Step 03] Loss_cls = 1.5866, Loss_grad = 34.6465, L2 = 0.1380, Dot = 0.0149, Cosine = 0.5588
[Epoch 1 | Batch 016 | Step 04] Loss_cls = 1.5758, Loss_grad = 26.8823, L2 = 0.1281, Dot = 0.0089, Cosine = 0.4336
[Epoch 1 | Batch 017 | Step 00] Loss_cls = 1.7982, Loss_grad = 62.0000, L2 = 0.2022, Dot = 0.0265, Cosine = 1.0000
[Epoch 1 | Batch 017 | Step 01] Loss_cls = 1.7343, Loss_grad = 61.9883, L2 = 0.1650, Dot = 0.0167, Cosine = 0.9998
[Epoch 1 | Batch 017 | Step 02] Loss_cls = 1.7703, Loss_grad = 52.2120, L2 = 0.1357, Dot = 0.0116, Cosine = 0.8421
[Epoch 1 | Batch 017 | Step 03] Loss_cls = 1.7971, Loss_grad = 28.7125, L2 = 0.1107, Dot = 0.0074, Cosine = 0.4631
[Epoch 1 | Batch 017 | Step 04] Loss_cls = 1.8283, Loss_grad = 11.0691, L2 = 0.1059, Dot = 0.0046, Cosine = 0.1785
[Epoch 1 | Batch 018 | Step 00] Loss_cls = 1.7142, Loss_grad = 62.0000, L2 = 0.1717, Dot = 0.0189, Cosine = 1.0000
[Epoch 1 | Batch 018 | Step 01] Loss_cls = 1.6708, Loss_grad = 61.9481, L2 = 0.1642, Dot = 0.0174, Cosine = 0.9992
[Epoch 1 | Batch 018 | Step 02] Loss_cls = 1.4677, Loss_grad = 42.4573, L2 = 0.1778, Dot = 0.0155, Cosine = 0.6848
[Epoch 1 | Batch 018 | Step 03] Loss_cls = 1.3066, Loss_grad = 28.4573, L2 = 0.2353, Dot = 0.0144, Cosine = 0.4590
[Epoch 1 | Batch 018 | Step 04] Loss_cls = 1.1319, Loss_grad = 23.2242, L2 = 0.2243, Dot = 0.0198, Cosine = 0.3746
[Epoch 1 | Batch 019 | Step 00] Loss_cls = 1.7363, Loss_grad = 62.0000, L2 = 0.2888, Dot = 0.0568, Cosine = 1.0000
[Epoch 1 | Batch 019 | Step 01] Loss_cls = 1.7006, Loss_grad = 61.9688, L2 = 0.2670, Dot = 0.0581, Cosine = 0.9995
[Epoch 1 | Batch 019 | Step 02] Loss_cls = 1.4470, Loss_grad = 49.8009, L2 = 0.1962, Dot = 0.0250, Cosine = 0.8032
[Epoch 1 | Batch 019 | Step 03] Loss_cls = 1.2114, Loss_grad = 7.3726, L2 = 0.1345, Dot = 0.0028, Cosine = 0.1189
[Epoch 1 | Batch 019 | Step 04] Loss_cls = 1.1508, Loss_grad = 19.6503, L2 = 0.2154, Dot = 0.0300, Cosine = 0.3169
[Epoch 1 | Batch 020 | Step 00] Loss_cls = 1.9541, Loss_grad = 62.0000, L2 = 0.3766, Dot = 0.1147, Cosine = 1.0000
[Epoch 1 | Batch 020 | Step 01] Loss_cls = 1.7282, Loss_grad = 61.9871, L2 = 0.2299, Dot = 0.0474, Cosine = 0.9998
[Epoch 1 | Batch 020 | Step 02] Loss_cls = 1.7789, Loss_grad = 51.3492, L2 = 0.2056, Dot = 0.0296, Cosine = 0.8282
[Epoch 1 | Batch 020 | Step 03] Loss_cls = 1.7728, Loss_grad = 37.4764, L2 = 0.1765, Dot = 0.0222, Cosine = 0.6045
[Epoch 1 | Batch 020 | Step 04] Loss_cls = 1.7419, Loss_grad = 35.9996, L2 = 0.1733, Dot = 0.0201, Cosine = 0.5806
[Epoch 1 | Batch 021 | Step 00] Loss_cls = 1.7294, Loss_grad = 62.0000, L2 = 0.1951, Dot = 0.0268, Cosine = 1.0000
[Epoch 1 | Batch 021 | Step 01] Loss_cls = 1.6933, Loss_grad = 61.9967, L2 = 0.1620, Dot = 0.0193, Cosine = 0.9999
[Epoch 1 | Batch 021 | Step 02] Loss_cls = 1.6504, Loss_grad = 58.9832, L2 = 0.1413, Dot = 0.0160, Cosine = 0.9513
[Epoch 1 | Batch 021 | Step 03] Loss_cls = 1.6060, Loss_grad = 51.6907, L2 = 0.1276, Dot = 0.0132, Cosine = 0.8337
[Epoch 1 | Batch 021 | Step 04] Loss_cls = 1.5642, Loss_grad = 40.2591, L2 = 0.1211, Dot = 0.0103, Cosine = 0.6493
[Epoch 1 | Batch 022 | Step 00] Loss_cls = 1.5692, Loss_grad = 62.0000, L2 = 0.1733, Dot = 0.0224, Cosine = 1.0000
[Epoch 1 | Batch 022 | Step 01] Loss_cls = 1.4994, Loss_grad = 61.9931, L2 = 0.1413, Dot = 0.0155, Cosine = 0.9999
[Epoch 1 | Batch 022 | Step 02] Loss_cls = 1.5039, Loss_grad = 47.5055, L2 = 0.1194, Dot = 0.0094, Cosine = 0.7662
[Epoch 1 | Batch 022 | Step 03] Loss_cls = 1.4913, Loss_grad = 25.7261, L2 = 0.1056, Dot = 0.0052, Cosine = 0.4149
[Epoch 1 | Batch 022 | Step 04] Loss_cls = 1.5136, Loss_grad = 19.1472, L2 = 0.1265, Dot = 0.0083, Cosine = 0.3088
[Epoch 1 | Batch 023 | Step 00] Loss_cls = 1.7693, Loss_grad = 62.0000, L2 = 0.2487, Dot = 0.0480, Cosine = 1.0000
[Epoch 1 | Batch 023 | Step 01] Loss_cls = 1.6062, Loss_grad = 61.9964, L2 = 0.1703, Dot = 0.0197, Cosine = 0.9999
[Epoch 1 | Batch 023 | Step 02] Loss_cls = 1.5063, Loss_grad = 53.6058, L2 = 0.1029, Dot = 0.0071, Cosine = 0.8646
[Epoch 1 | Batch 023 | Step 03] Loss_cls = 1.5228, Loss_grad = 46.1938, L2 = 0.1381, Dot = 0.0149, Cosine = 0.7451
[Epoch 1 | Batch 023 | Step 04] Loss_cls = 1.5418, Loss_grad = 34.9766, L2 = 0.1513, Dot = 0.0142, Cosine = 0.5641
[Epoch 1 | Batch 024 | Step 00] Loss_cls = 1.7600, Loss_grad = 62.0000, L2 = 0.2427, Dot = 0.0467, Cosine = 1.0000
[Epoch 1 | Batch 024 | Step 01] Loss_cls = 1.6270, Loss_grad = 61.9935, L2 = 0.1475, Dot = 0.0152, Cosine = 0.9999
[Epoch 1 | Batch 024 | Step 02] Loss_cls = 1.6316, Loss_grad = 55.6842, L2 = 0.1412, Dot = 0.0145, Cosine = 0.8981
[Epoch 1 | Batch 024 | Step 03] Loss_cls = 1.6627, Loss_grad = 43.5666, L2 = 0.1475, Dot = 0.0172, Cosine = 0.7027
[Epoch 1 | Batch 024 | Step 04] Loss_cls = 1.6628, Loss_grad = 21.0401, L2 = 0.1407, Dot = 0.0167, Cosine = 0.3394
[Epoch 1 | Batch 025 | Step 00] Loss_cls = 1.6071, Loss_grad = 62.0000, L2 = 0.1599, Dot = 0.0191, Cosine = 1.0000
[Epoch 1 | Batch 025 | Step 01] Loss_cls = 1.5376, Loss_grad = 61.9944, L2 = 0.1157, Dot = 0.0081, Cosine = 0.9999
[Epoch 1 | Batch 025 | Step 02] Loss_cls = 1.4439, Loss_grad = 52.1799, L2 = 0.1061, Dot = 0.0080, Cosine = 0.8416
[Epoch 1 | Batch 025 | Step 03] Loss_cls = 1.4106, Loss_grad = 36.0324, L2 = 0.1071, Dot = 0.0091, Cosine = 0.5812
[Epoch 1 | Batch 025 | Step 04] Loss_cls = 1.3638, Loss_grad = 18.2389, L2 = 0.1050, Dot = 0.0066, Cosine = 0.2942
[Epoch 1 | Batch 026 | Step 00] Loss_cls = 1.6465, Loss_grad = 62.0000, L2 = 0.1645, Dot = 0.0214, Cosine = 1.0000
[Epoch 1 | Batch 026 | Step 01] Loss_cls = 1.5634, Loss_grad = 61.9945, L2 = 0.1473, Dot = 0.0148, Cosine = 0.9999
[Epoch 1 | Batch 026 | Step 02] Loss_cls = 1.6178, Loss_grad = 52.7552, L2 = 0.1334, Dot = 0.0113, Cosine = 0.8509
[Epoch 1 | Batch 026 | Step 03] Loss_cls = 1.6841, Loss_grad = 36.7791, L2 = 0.1276, Dot = 0.0107, Cosine = 0.5932
[Epoch 1 | Batch 026 | Step 04] Loss_cls = 1.7177, Loss_grad = 16.1273, L2 = 0.1151, Dot = 0.0073, Cosine = 0.2601
[Epoch 1 | Batch 027 | Step 00] Loss_cls = 1.6220, Loss_grad = 62.0000, L2 = 0.1569, Dot = 0.0188, Cosine = 1.0000
[Epoch 1 | Batch 027 | Step 01] Loss_cls = 1.5522, Loss_grad = 61.9919, L2 = 0.1216, Dot = 0.0096, Cosine = 0.9999
[Epoch 1 | Batch 027 | Step 02] Loss_cls = 1.5463, Loss_grad = 50.1404, L2 = 0.1177, Dot = 0.0144, Cosine = 0.8087
[Epoch 1 | Batch 027 | Step 03] Loss_cls = 1.5528, Loss_grad = 30.2094, L2 = 0.1142, Dot = 0.0113, Cosine = 0.4872
[Epoch 1 | Batch 027 | Step 04] Loss_cls = 1.5661, Loss_grad = 10.2972, L2 = 0.1097, Dot = 0.0060, Cosine = 0.1661
[Epoch 1 | Batch 028 | Step 00] Loss_cls = 1.6892, Loss_grad = 62.0000, L2 = 0.1945, Dot = 0.0277, Cosine = 1.0000
[Epoch 1 | Batch 028 | Step 01] Loss_cls = 1.6267, Loss_grad = 61.9940, L2 = 0.1547, Dot = 0.0164, Cosine = 0.9999
[Epoch 1 | Batch 028 | Step 02] Loss_cls = 1.5267, Loss_grad = 54.9933, L2 = 0.1217, Dot = 0.0112, Cosine = 0.8870
[Epoch 1 | Batch 028 | Step 03] Loss_cls = 1.4896, Loss_grad = 40.4062, L2 = 0.1096, Dot = 0.0098, Cosine = 0.6517
[Epoch 1 | Batch 028 | Step 04] Loss_cls = 1.4790, Loss_grad = 29.4484, L2 = 0.1092, Dot = 0.0085, Cosine = 0.4750
[Epoch 1 | Batch 029 | Step 00] Loss_cls = 1.6015, Loss_grad = 62.0000, L2 = 0.1296, Dot = 0.0120, Cosine = 1.0000
[Epoch 1 | Batch 029 | Step 01] Loss_cls = 1.5493, Loss_grad = 61.9929, L2 = 0.1113, Dot = 0.0084, Cosine = 0.9999
[Epoch 1 | Batch 029 | Step 02] Loss_cls = 1.6050, Loss_grad = 45.3093, L2 = 0.0969, Dot = 0.0049, Cosine = 0.7308
[Epoch 1 | Batch 029 | Step 03] Loss_cls = 1.6505, Loss_grad = 17.1268, L2 = 0.0920, Dot = 0.0038, Cosine = 0.2762
[Epoch 1 | Batch 029 | Step 04] Loss_cls = 1.6970, Loss_grad = -3.1432, L2 = 0.0969, Dot = 0.0048, Cosine = -0.0507
[Epoch 1 | Batch 030 | Step 00] Loss_cls = 1.7213, Loss_grad = 62.0000, L2 = 0.1905, Dot = 0.0317, Cosine = 1.0000
[Epoch 1 | Batch 030 | Step 01] Loss_cls = 1.6298, Loss_grad = 61.9929, L2 = 0.1462, Dot = 0.0153, Cosine = 0.9999
[Epoch 1 | Batch 030 | Step 02] Loss_cls = 1.4774, Loss_grad = 56.5816, L2 = 0.1182, Dot = 0.0079, Cosine = 0.9126
[Epoch 1 | Batch 030 | Step 03] Loss_cls = 1.4232, Loss_grad = 43.7999, L2 = 0.1037, Dot = 0.0059, Cosine = 0.7064
[Epoch 1 | Batch 030 | Step 04] Loss_cls = 1.3965, Loss_grad = 17.8154, L2 = 0.1001, Dot = 0.0060, Cosine = 0.2873
[Epoch 1 | Batch 031 | Step 00] Loss_cls = 1.6427, Loss_grad = 62.0000, L2 = 0.1334, Dot = 0.0128, Cosine = 1.0000
[Epoch 1 | Batch 031 | Step 01] Loss_cls = 1.6178, Loss_grad = 61.9892, L2 = 0.1348, Dot = 0.0129, Cosine = 0.9998
[Epoch 1 | Batch 031 | Step 02] Loss_cls = 1.4972, Loss_grad = 53.3632, L2 = 0.1231, Dot = 0.0095, Cosine = 0.8607
[Epoch 1 | Batch 031 | Step 03] Loss_cls = 1.4299, Loss_grad = 36.9123, L2 = 0.1125, Dot = 0.0064, Cosine = 0.5954
[Epoch 1 | Batch 031 | Step 04] Loss_cls = 1.3869, Loss_grad = 9.6723, L2 = 0.0994, Dot = 0.0030, Cosine = 0.1560
[Epoch 1 | Batch 032 | Step 00] Loss_cls = 1.4943, Loss_grad = 62.0000, L2 = 0.1363, Dot = 0.0128, Cosine = 1.0000
[Epoch 1 | Batch 032 | Step 01] Loss_cls = 1.4927, Loss_grad = 61.9939, L2 = 0.1455, Dot = 0.0151, Cosine = 0.9999
[Epoch 1 | Batch 032 | Step 02] Loss_cls = 1.4697, Loss_grad = 54.1076, L2 = 0.1384, Dot = 0.0125, Cosine = 0.8727
[Epoch 1 | Batch 032 | Step 03] Loss_cls = 1.4070, Loss_grad = 32.8703, L2 = 0.1107, Dot = 0.0054, Cosine = 0.5302
[Epoch 1 | Batch 032 | Step 04] Loss_cls = 1.3619, Loss_grad = 14.2879, L2 = 0.1067, Dot = 0.0035, Cosine = 0.2305
[Epoch 1 | Batch 033 | Step 00] Loss_cls = 1.5236, Loss_grad = 62.0000, L2 = 0.2145, Dot = 0.0331, Cosine = 1.0000
[Epoch 1 | Batch 033 | Step 01] Loss_cls = 1.4534, Loss_grad = 61.9803, L2 = 0.1775, Dot = 0.0216, Cosine = 0.9997
[Epoch 1 | Batch 033 | Step 02] Loss_cls = 1.3426, Loss_grad = 54.4376, L2 = 0.1491, Dot = 0.0137, Cosine = 0.8780
[Epoch 1 | Batch 033 | Step 03] Loss_cls = 1.3127, Loss_grad = 37.5074, L2 = 0.1286, Dot = 0.0087, Cosine = 0.6050
[Epoch 1 | Batch 033 | Step 04] Loss_cls = 1.3160, Loss_grad = 11.5770, L2 = 0.1156, Dot = 0.0045, Cosine = 0.1867
[Epoch 1 | Batch 034 | Step 00] Loss_cls = 1.6425, Loss_grad = 62.0000, L2 = 0.2359, Dot = 0.0372, Cosine = 1.0000
[Epoch 1 | Batch 034 | Step 01] Loss_cls = 1.5591, Loss_grad = 61.9708, L2 = 0.1897, Dot = 0.0226, Cosine = 0.9995
[Epoch 1 | Batch 034 | Step 02] Loss_cls = 1.3107, Loss_grad = 47.1034, L2 = 0.1280, Dot = 0.0090, Cosine = 0.7597
[Epoch 1 | Batch 034 | Step 03] Loss_cls = 1.2245, Loss_grad = 23.8396, L2 = 0.0991, Dot = 0.0051, Cosine = 0.3845
[Epoch 1 | Batch 034 | Step 04] Loss_cls = 1.2432, Loss_grad = 18.5355, L2 = 0.1176, Dot = 0.0075, Cosine = 0.2990
[Epoch 1 | Batch 035 | Step 00] Loss_cls = 1.5565, Loss_grad = 62.0000, L2 = 0.1990, Dot = 0.0276, Cosine = 1.0000
[Epoch 1 | Batch 035 | Step 01] Loss_cls = 1.4711, Loss_grad = 61.9962, L2 = 0.1527, Dot = 0.0156, Cosine = 0.9999
[Epoch 1 | Batch 035 | Step 02] Loss_cls = 1.3208, Loss_grad = 53.0083, L2 = 0.1090, Dot = 0.0067, Cosine = 0.8550
[Epoch 1 | Batch 035 | Step 03] Loss_cls = 1.2904, Loss_grad = 40.9584, L2 = 0.1107, Dot = 0.0061, Cosine = 0.6606
[Epoch 1 | Batch 035 | Step 04] Loss_cls = 1.3114, Loss_grad = 19.3766, L2 = 0.1102, Dot = 0.0047, Cosine = 0.3125
[Epoch 1 | Batch 036 | Step 00] Loss_cls = 1.4729, Loss_grad = 62.0000, L2 = 0.1494, Dot = 0.0144, Cosine = 1.0000
[Epoch 1 | Batch 036 | Step 01] Loss_cls = 1.4396, Loss_grad = 61.9916, L2 = 0.1469, Dot = 0.0134, Cosine = 0.9999
[Epoch 1 | Batch 036 | Step 02] Loss_cls = 1.5076, Loss_grad = 46.6684, L2 = 0.1467, Dot = 0.0108, Cosine = 0.7527
[Epoch 1 | Batch 036 | Step 03] Loss_cls = 1.4717, Loss_grad = 9.0770, L2 = 0.1100, Dot = 0.0027, Cosine = 0.1464
[Epoch 1 | Batch 036 | Step 04] Loss_cls = 1.4066, Loss_grad = -16.3958, L2 = 0.0872, Dot = -0.0012, Cosine = -0.2644
[Epoch 1 | Batch 037 | Step 00] Loss_cls = 1.5672, Loss_grad = 62.0000, L2 = 0.1871, Dot = 0.0205, Cosine = 1.0000
[Epoch 1 | Batch 037 | Step 01] Loss_cls = 1.5697, Loss_grad = 61.9814, L2 = 0.1760, Dot = 0.0179, Cosine = 0.9997
[Epoch 1 | Batch 037 | Step 02] Loss_cls = 1.6227, Loss_grad = 51.5346, L2 = 0.1468, Dot = 0.0113, Cosine = 0.8312
[Epoch 1 | Batch 037 | Step 03] Loss_cls = 1.5714, Loss_grad = 25.9322, L2 = 0.0983, Dot = 0.0035, Cosine = 0.4183
[Epoch 1 | Batch 037 | Step 04] Loss_cls = 1.5480, Loss_grad = 13.2575, L2 = 0.0847, Dot = 0.0023, Cosine = 0.2138
[Epoch 1 | Batch 038 | Step 00] Loss_cls = 1.5563, Loss_grad = 62.0000, L2 = 0.1302, Dot = 0.0113, Cosine = 1.0000
[Epoch 1 | Batch 038 | Step 01] Loss_cls = 1.5534, Loss_grad = 61.9971, L2 = 0.1214, Dot = 0.0099, Cosine = 1.0000
[Epoch 1 | Batch 038 | Step 02] Loss_cls = 1.4834, Loss_grad = 57.8155, L2 = 0.1046, Dot = 0.0066, Cosine = 0.9325
[Epoch 1 | Batch 038 | Step 03] Loss_cls = 1.4688, Loss_grad = 42.8393, L2 = 0.0887, Dot = 0.0038, Cosine = 0.6910
[Epoch 1 | Batch 038 | Step 04] Loss_cls = 1.4847, Loss_grad = 19.9381, L2 = 0.0876, Dot = 0.0028, Cosine = 0.3216
[Epoch 1 | Batch 039 | Step 00] Loss_cls = 1.6390, Loss_grad = 62.0000, L2 = 0.1650, Dot = 0.0174, Cosine = 1.0000
[Epoch 1 | Batch 039 | Step 01] Loss_cls = 1.6043, Loss_grad = 61.9961, L2 = 0.1574, Dot = 0.0156, Cosine = 0.9999
[Epoch 1 | Batch 039 | Step 02] Loss_cls = 1.5924, Loss_grad = 56.4713, L2 = 0.1348, Dot = 0.0102, Cosine = 0.9108
[Epoch 1 | Batch 039 | Step 03] Loss_cls = 1.5804, Loss_grad = 38.6125, L2 = 0.1026, Dot = 0.0049, Cosine = 0.6228
[Epoch 1 | Batch 039 | Step 04] Loss_cls = 1.6073, Loss_grad = 20.2374, L2 = 0.0962, Dot = 0.0042, Cosine = 0.3264
[Epoch 1 | Batch 040 | Step 00] Loss_cls = 1.5113, Loss_grad = 62.0000, L2 = 0.1392, Dot = 0.0121, Cosine = 1.0000
[Epoch 1 | Batch 040 | Step 01] Loss_cls = 1.4962, Loss_grad = 61.9963, L2 = 0.1340, Dot = 0.0109, Cosine = 0.9999
[Epoch 1 | Batch 040 | Step 02] Loss_cls = 1.3671, Loss_grad = 58.5405, L2 = 0.1203, Dot = 0.0081, Cosine = 0.9442
[Epoch 1 | Batch 040 | Step 03] Loss_cls = 1.3083, Loss_grad = 48.7061, L2 = 0.1060, Dot = 0.0056, Cosine = 0.7856
[Epoch 1 | Batch 040 | Step 04] Loss_cls = 1.2835, Loss_grad = 33.5216, L2 = 0.1078, Dot = 0.0052, Cosine = 0.5407
[Epoch 1 | Batch 041 | Step 00] Loss_cls = 1.5493, Loss_grad = 62.0000, L2 = 0.1604, Dot = 0.0170, Cosine = 1.0000
[Epoch 1 | Batch 041 | Step 01] Loss_cls = 1.4878, Loss_grad = 61.9940, L2 = 0.1334, Dot = 0.0113, Cosine = 0.9999
[Epoch 1 | Batch 041 | Step 02] Loss_cls = 1.2996, Loss_grad = 49.3588, L2 = 0.0872, Dot = 0.0042, Cosine = 0.7961
[Epoch 1 | Batch 041 | Step 03] Loss_cls = 1.2643, Loss_grad = 35.5477, L2 = 0.0996, Dot = 0.0050, Cosine = 0.5733
[Epoch 1 | Batch 041 | Step 04] Loss_cls = 1.2622, Loss_grad = 23.6316, L2 = 0.1152, Dot = 0.0056, Cosine = 0.3812
[Epoch 1 | Batch 042 | Step 00] Loss_cls = 1.4362, Loss_grad = 62.0000, L2 = 0.1543, Dot = 0.0156, Cosine = 1.0000
[Epoch 1 | Batch 042 | Step 01] Loss_cls = 1.3844, Loss_grad = 61.9798, L2 = 0.1325, Dot = 0.0107, Cosine = 0.9997
[Epoch 1 | Batch 042 | Step 02] Loss_cls = 1.4413, Loss_grad = 48.8894, L2 = 0.1267, Dot = 0.0076, Cosine = 0.7885
[Epoch 1 | Batch 042 | Step 03] Loss_cls = 1.4845, Loss_grad = 29.3471, L2 = 0.1327, Dot = 0.0058, Cosine = 0.4733
[Epoch 1 | Batch 042 | Step 04] Loss_cls = 1.4544, Loss_grad = -5.2426, L2 = 0.1116, Dot = -0.0001, Cosine = -0.0846
[Epoch 1 | Batch 043 | Step 00] Loss_cls = 1.5579, Loss_grad = 62.0000, L2 = 0.2123, Dot = 0.0288, Cosine = 1.0000
[Epoch 1 | Batch 043 | Step 01] Loss_cls = 1.5315, Loss_grad = 61.9952, L2 = 0.1989, Dot = 0.0241, Cosine = 0.9999
[Epoch 1 | Batch 043 | Step 02] Loss_cls = 1.6238, Loss_grad = 55.4788, L2 = 0.1638, Dot = 0.0148, Cosine = 0.8948
[Epoch 1 | Batch 043 | Step 03] Loss_cls = 1.6264, Loss_grad = 30.8640, L2 = 0.1109, Dot = 0.0048, Cosine = 0.4978
[Epoch 1 | Batch 043 | Step 04] Loss_cls = 1.6439, Loss_grad = 3.4299, L2 = 0.0900, Dot = 0.0025, Cosine = 0.0553
[Epoch 1 | Batch 044 | Step 00] Loss_cls = 1.4619, Loss_grad = 62.0000, L2 = 0.1206, Dot = 0.0100, Cosine = 1.0000
[Epoch 1 | Batch 044 | Step 01] Loss_cls = 1.5002, Loss_grad = 61.9948, L2 = 0.1280, Dot = 0.0105, Cosine = 0.9999
[Epoch 1 | Batch 044 | Step 02] Loss_cls = 1.5683, Loss_grad = 57.0858, L2 = 0.1175, Dot = 0.0080, Cosine = 0.9207
[Epoch 1 | Batch 044 | Step 03] Loss_cls = 1.6205, Loss_grad = 41.7585, L2 = 0.0997, Dot = 0.0049, Cosine = 0.6735
[Epoch 1 | Batch 044 | Step 04] Loss_cls = 1.6779, Loss_grad = 19.2361, L2 = 0.0887, Dot = 0.0030, Cosine = 0.3103
[Epoch 1 | Batch 045 | Step 00] Loss_cls = 1.4935, Loss_grad = 62.0000, L2 = 0.1104, Dot = 0.0077, Cosine = 1.0000
[Epoch 1 | Batch 045 | Step 01] Loss_cls = 1.4853, Loss_grad = 61.9933, L2 = 0.1029, Dot = 0.0066, Cosine = 0.9999
[Epoch 1 | Batch 045 | Step 02] Loss_cls = 1.4102, Loss_grad = 58.1253, L2 = 0.0996, Dot = 0.0055, Cosine = 0.9375
[Epoch 1 | Batch 045 | Step 03] Loss_cls = 1.3607, Loss_grad = 52.8200, L2 = 0.0989, Dot = 0.0048, Cosine = 0.8519
[Epoch 1 | Batch 045 | Step 04] Loss_cls = 1.3125, Loss_grad = 43.4513, L2 = 0.0993, Dot = 0.0042, Cosine = 0.7008
[Epoch 1 | Batch 046 | Step 00] Loss_cls = 1.4413, Loss_grad = 62.0000, L2 = 0.1041, Dot = 0.0067, Cosine = 1.0000
[Epoch 1 | Batch 046 | Step 01] Loss_cls = 1.4055, Loss_grad = 61.9955, L2 = 0.1041, Dot = 0.0067, Cosine = 0.9999
[Epoch 1 | Batch 046 | Step 02] Loss_cls = 1.2952, Loss_grad = 53.8303, L2 = 0.1007, Dot = 0.0057, Cosine = 0.8682
[Epoch 1 | Batch 046 | Step 03] Loss_cls = 1.2132, Loss_grad = 39.4926, L2 = 0.0955, Dot = 0.0039, Cosine = 0.6370
[Epoch 1 | Batch 046 | Step 04] Loss_cls = 1.1527, Loss_grad = 17.5901, L2 = 0.0928, Dot = 0.0008, Cosine = 0.2837
[Epoch 1 | Batch 047 | Step 00] Loss_cls = 1.4406, Loss_grad = 62.0000, L2 = 0.1719, Dot = 0.0197, Cosine = 1.0000
[Epoch 1 | Batch 047 | Step 01] Loss_cls = 1.3749, Loss_grad = 61.9466, L2 = 0.1376, Dot = 0.0118, Cosine = 0.9991
[Epoch 1 | Batch 047 | Step 02] Loss_cls = 1.1490, Loss_grad = 41.2011, L2 = 0.1307, Dot = 0.0080, Cosine = 0.6645
[Epoch 1 | Batch 047 | Step 03] Loss_cls = 1.0459, Loss_grad = 25.3784, L2 = 0.1398, Dot = 0.0106, Cosine = 0.4093
[Epoch 1 | Batch 047 | Step 04] Loss_cls = 0.9406, Loss_grad = -2.5874, L2 = 0.1304, Dot = 0.0040, Cosine = -0.0417
[Epoch 1 | Batch 048 | Step 00] Loss_cls = 1.5160, Loss_grad = 62.0000, L2 = 0.2717, Dot = 0.0469, Cosine = 1.0000
[Epoch 1 | Batch 048 | Step 01] Loss_cls = 1.3667, Loss_grad = 61.9756, L2 = 0.1959, Dot = 0.0253, Cosine = 0.9996
[Epoch 1 | Batch 048 | Step 02] Loss_cls = 1.3248, Loss_grad = 45.7434, L2 = 0.1456, Dot = 0.0137, Cosine = 0.7378
[Epoch 1 | Batch 048 | Step 03] Loss_cls = 1.3556, Loss_grad = 15.9854, L2 = 0.1170, Dot = 0.0061, Cosine = 0.2578
[Epoch 1 | Batch 048 | Step 04] Loss_cls = 1.4627, Loss_grad = 2.5282, L2 = 0.1346, Dot = 0.0104, Cosine = 0.0408
[Epoch 1 | Batch 049 | Step 00] Loss_cls = 1.5416, Loss_grad = 62.0000, L2 = 0.2235, Dot = 0.0324, Cosine = 1.0000
[Epoch 1 | Batch 049 | Step 01] Loss_cls = 1.4807, Loss_grad = 61.9959, L2 = 0.1875, Dot = 0.0207, Cosine = 0.9999
[Epoch 1 | Batch 049 | Step 02] Loss_cls = 1.4513, Loss_grad = 54.5371, L2 = 0.1532, Dot = 0.0142, Cosine = 0.8796
[Epoch 1 | Batch 049 | Step 03] Loss_cls = 1.4389, Loss_grad = 36.7963, L2 = 0.1354, Dot = 0.0137, Cosine = 0.5935
[Epoch 1 | Batch 049 | Step 04] Loss_cls = 1.4291, Loss_grad = 20.9874, L2 = 0.1179, Dot = 0.0094, Cosine = 0.3385
[Epoch 1 | Batch 050 | Step 00] Loss_cls = 1.4677, Loss_grad = 62.0000, L2 = 0.1594, Dot = 0.0205, Cosine = 1.0000
[Epoch 1 | Batch 050 | Step 01] Loss_cls = 1.4399, Loss_grad = 61.9940, L2 = 0.1481, Dot = 0.0163, Cosine = 0.9999
[Epoch 1 | Batch 050 | Step 02] Loss_cls = 1.4712, Loss_grad = 56.3021, L2 = 0.1282, Dot = 0.0111, Cosine = 0.9081
[Epoch 1 | Batch 050 | Step 03] Loss_cls = 1.5318, Loss_grad = 42.3992, L2 = 0.1417, Dot = 0.0189, Cosine = 0.6839
[Epoch 1 | Batch 050 | Step 04] Loss_cls = 1.5356, Loss_grad = 20.0439, L2 = 0.1183, Dot = 0.0103, Cosine = 0.3233
[Epoch 1 | Batch 051 | Step 00] Loss_cls = 1.4587, Loss_grad = 62.0000, L2 = 0.1717, Dot = 0.0249, Cosine = 1.0000
[Epoch 1 | Batch 051 | Step 01] Loss_cls = 1.4169, Loss_grad = 61.9933, L2 = 0.1495, Dot = 0.0161, Cosine = 0.9999
[Epoch 1 | Batch 051 | Step 02] Loss_cls = 1.3677, Loss_grad = 54.8059, L2 = 0.1354, Dot = 0.0150, Cosine = 0.8840
[Epoch 1 | Batch 051 | Step 03] Loss_cls = 1.3505, Loss_grad = 37.4211, L2 = 0.1227, Dot = 0.0115, Cosine = 0.6036
[Epoch 1 | Batch 051 | Step 04] Loss_cls = 1.3413, Loss_grad = 20.5106, L2 = 0.1149, Dot = 0.0058, Cosine = 0.3308
[Epoch 1 | Batch 052 | Step 00] Loss_cls = 1.5025, Loss_grad = 62.0000, L2 = 0.1678, Dot = 0.0206, Cosine = 1.0000
[Epoch 1 | Batch 052 | Step 01] Loss_cls = 1.4448, Loss_grad = 61.9863, L2 = 0.1316, Dot = 0.0109, Cosine = 0.9998
[Epoch 1 | Batch 052 | Step 02] Loss_cls = 1.4358, Loss_grad = 55.2969, L2 = 0.1381, Dot = 0.0130, Cosine = 0.8919
[Epoch 1 | Batch 052 | Step 03] Loss_cls = 1.4742, Loss_grad = 45.9092, L2 = 0.1338, Dot = 0.0124, Cosine = 0.7405
[Epoch 1 | Batch 052 | Step 04] Loss_cls = 1.4965, Loss_grad = 27.7911, L2 = 0.1182, Dot = 0.0088, Cosine = 0.4482
[Epoch 1 | Batch 053 | Step 00] Loss_cls = 1.4447, Loss_grad = 62.0000, L2 = 0.1650, Dot = 0.0218, Cosine = 1.0000
[Epoch 1 | Batch 053 | Step 01] Loss_cls = 1.3662, Loss_grad = 61.9908, L2 = 0.1289, Dot = 0.0105, Cosine = 0.9999
[Epoch 1 | Batch 053 | Step 02] Loss_cls = 1.3167, Loss_grad = 48.6488, L2 = 0.1280, Dot = 0.0109, Cosine = 0.7847
[Epoch 1 | Batch 053 | Step 03] Loss_cls = 1.3147, Loss_grad = 25.1951, L2 = 0.1384, Dot = 0.0151, Cosine = 0.4064
[Epoch 1 | Batch 053 | Step 04] Loss_cls = 1.2862, Loss_grad = -1.1104, L2 = 0.1245, Dot = 0.0074, Cosine = -0.0179
[Epoch 1 | Batch 054 | Step 00] Loss_cls = 1.4371, Loss_grad = 62.0000, L2 = 0.1833, Dot = 0.0237, Cosine = 1.0000
[Epoch 1 | Batch 054 | Step 01] Loss_cls = 1.3615, Loss_grad = 61.9881, L2 = 0.1454, Dot = 0.0126, Cosine = 0.9998
[Epoch 1 | Batch 054 | Step 02] Loss_cls = 1.4189, Loss_grad = 49.6956, L2 = 0.1341, Dot = 0.0096, Cosine = 0.8015
[Epoch 1 | Batch 054 | Step 03] Loss_cls = 1.4708, Loss_grad = 26.6486, L2 = 0.1282, Dot = 0.0086, Cosine = 0.4298
[Epoch 1 | Batch 054 | Step 04] Loss_cls = 1.5221, Loss_grad = 9.8357, L2 = 0.1197, Dot = 0.0066, Cosine = 0.1586
[Epoch 1 | Batch 055 | Step 00] Loss_cls = 1.5768, Loss_grad = 62.0000, L2 = 0.1945, Dot = 0.0262, Cosine = 1.0000
[Epoch 1 | Batch 055 | Step 01] Loss_cls = 1.5210, Loss_grad = 61.9963, L2 = 0.1802, Dot = 0.0219, Cosine = 0.9999
[Epoch 1 | Batch 055 | Step 02] Loss_cls = 1.3954, Loss_grad = 57.5113, L2 = 0.1394, Dot = 0.0125, Cosine = 0.9276
[Epoch 1 | Batch 055 | Step 03] Loss_cls = 1.3745, Loss_grad = 47.9172, L2 = 0.1161, Dot = 0.0070, Cosine = 0.7729
[Epoch 1 | Batch 055 | Step 04] Loss_cls = 1.4778, Loss_grad = 41.2688, L2 = 0.1397, Dot = 0.0116, Cosine = 0.6656
[Epoch 1 | Batch 056 | Step 00] Loss_cls = 1.4027, Loss_grad = 62.0000, L2 = 0.1597, Dot = 0.0211, Cosine = 1.0000
[Epoch 1 | Batch 056 | Step 01] Loss_cls = 1.3339, Loss_grad = 61.9770, L2 = 0.1274, Dot = 0.0114, Cosine = 0.9996
[Epoch 1 | Batch 056 | Step 02] Loss_cls = 1.2437, Loss_grad = 55.8356, L2 = 0.1157, Dot = 0.0071, Cosine = 0.9006
[Epoch 1 | Batch 056 | Step 03] Loss_cls = 1.2043, Loss_grad = 47.9945, L2 = 0.1194, Dot = 0.0072, Cosine = 0.7741
[Epoch 1 | Batch 056 | Step 04] Loss_cls = 1.1442, Loss_grad = 29.9493, L2 = 0.1206, Dot = 0.0072, Cosine = 0.4831
[Epoch 1 | Batch 057 | Step 00] Loss_cls = 1.3279, Loss_grad = 62.0000, L2 = 0.1467, Dot = 0.0176, Cosine = 1.0000
[Epoch 1 | Batch 057 | Step 01] Loss_cls = 1.2627, Loss_grad = 61.9810, L2 = 0.1253, Dot = 0.0101, Cosine = 0.9997
[Epoch 1 | Batch 057 | Step 02] Loss_cls = 1.1626, Loss_grad = 48.8886, L2 = 0.1085, Dot = 0.0065, Cosine = 0.7885
[Epoch 1 | Batch 057 | Step 03] Loss_cls = 1.1091, Loss_grad = 18.9507, L2 = 0.1018, Dot = 0.0050, Cosine = 0.3057
[Epoch 1 | Batch 057 | Step 04] Loss_cls = 1.1153, Loss_grad = -7.5588, L2 = 0.1038, Dot = 0.0037, Cosine = -0.1219
[Epoch 1 | Batch 058 | Step 00] Loss_cls = 1.3902, Loss_grad = 62.0000, L2 = 0.2048, Dot = 0.0313, Cosine = 1.0000
[Epoch 1 | Batch 058 | Step 01] Loss_cls = 1.3069, Loss_grad = 61.9875, L2 = 0.1606, Dot = 0.0156, Cosine = 0.9998
[Epoch 1 | Batch 058 | Step 02] Loss_cls = 1.2757, Loss_grad = 52.6428, L2 = 0.1409, Dot = 0.0102, Cosine = 0.8491
[Epoch 1 | Batch 058 | Step 03] Loss_cls = 1.2793, Loss_grad = 39.2142, L2 = 0.1464, Dot = 0.0128, Cosine = 0.6325
[Epoch 1 | Batch 058 | Step 04] Loss_cls = 1.2839, Loss_grad = 15.0603, L2 = 0.1236, Dot = 0.0068, Cosine = 0.2429
[Epoch 1 | Batch 059 | Step 00] Loss_cls = 1.3894, Loss_grad = 62.0000, L2 = 0.1816, Dot = 0.0202, Cosine = 1.0000
[Epoch 1 | Batch 059 | Step 01] Loss_cls = 1.3811, Loss_grad = 61.9867, L2 = 0.1809, Dot = 0.0196, Cosine = 0.9998
[Epoch 1 | Batch 059 | Step 02] Loss_cls = 1.5290, Loss_grad = 54.3272, L2 = 0.1677, Dot = 0.0157, Cosine = 0.8762
[Epoch 1 | Batch 059 | Step 03] Loss_cls = 1.5231, Loss_grad = 33.2063, L2 = 0.1293, Dot = 0.0071, Cosine = 0.5356
[Epoch 1 | Batch 059 | Step 04] Loss_cls = 1.5210, Loss_grad = 13.9475, L2 = 0.1120, Dot = 0.0042, Cosine = 0.2250
[Epoch 1 | Batch 060 | Step 00] Loss_cls = 1.3938, Loss_grad = 62.0000, L2 = 0.1564, Dot = 0.0175, Cosine = 1.0000
[Epoch 1 | Batch 060 | Step 01] Loss_cls = 1.3682, Loss_grad = 61.9909, L2 = 0.1365, Dot = 0.0129, Cosine = 0.9999
[Epoch 1 | Batch 060 | Step 02] Loss_cls = 1.3300, Loss_grad = 56.2765, L2 = 0.1191, Dot = 0.0085, Cosine = 0.9077
[Epoch 1 | Batch 060 | Step 03] Loss_cls = 1.3401, Loss_grad = 44.2732, L2 = 0.1074, Dot = 0.0059, Cosine = 0.7141
[Epoch 1 | Batch 060 | Step 04] Loss_cls = 1.3619, Loss_grad = 26.9464, L2 = 0.1058, Dot = 0.0050, Cosine = 0.4346
[Epoch 1 | Batch 061 | Step 00] Loss_cls = 1.4144, Loss_grad = 62.0000, L2 = 0.1426, Dot = 0.0139, Cosine = 1.0000
[Epoch 1 | Batch 061 | Step 01] Loss_cls = 1.4099, Loss_grad = 61.9937, L2 = 0.1410, Dot = 0.0131, Cosine = 0.9999
[Epoch 1 | Batch 061 | Step 02] Loss_cls = 1.4993, Loss_grad = 54.1877, L2 = 0.1244, Dot = 0.0090, Cosine = 0.8740
[Epoch 1 | Batch 061 | Step 03] Loss_cls = 1.5735, Loss_grad = 33.6676, L2 = 0.1079, Dot = 0.0059, Cosine = 0.5430
[Epoch 1 | Batch 061 | Step 04] Loss_cls = 1.6573, Loss_grad = 10.8267, L2 = 0.1033, Dot = 0.0052, Cosine = 0.1746
[Epoch 1 | Batch 062 | Step 00] Loss_cls = 1.5472, Loss_grad = 62.0000, L2 = 0.1458, Dot = 0.0168, Cosine = 1.0000
[Epoch 1 | Batch 062 | Step 01] Loss_cls = 1.5158, Loss_grad = 61.9954, L2 = 0.1321, Dot = 0.0123, Cosine = 0.9999
[Epoch 1 | Batch 062 | Step 02] Loss_cls = 1.3887, Loss_grad = 56.3632, L2 = 0.1158, Dot = 0.0079, Cosine = 0.9091
[Epoch 1 | Batch 062 | Step 03] Loss_cls = 1.3259, Loss_grad = 46.3097, L2 = 0.1060, Dot = 0.0058, Cosine = 0.7469
[Epoch 1 | Batch 062 | Step 04] Loss_cls = 1.2992, Loss_grad = 30.8491, L2 = 0.0980, Dot = 0.0047, Cosine = 0.4976
[Epoch 1 | Batch 063 | Step 00] Loss_cls = 1.4756, Loss_grad = 62.0000, L2 = 0.1445, Dot = 0.0189, Cosine = 1.0000
[Epoch 1 | Batch 063 | Step 01] Loss_cls = 1.4057, Loss_grad = 61.9900, L2 = 0.1259, Dot = 0.0132, Cosine = 0.9998
[Epoch 1 | Batch 063 | Step 02] Loss_cls = 1.3118, Loss_grad = 53.3270, L2 = 0.0988, Dot = 0.0061, Cosine = 0.8601
[Epoch 1 | Batch 063 | Step 03] Loss_cls = 1.2888, Loss_grad = 39.0140, L2 = 0.1041, Dot = 0.0073, Cosine = 0.6293
[Epoch 1 | Batch 063 | Step 04] Loss_cls = 1.2918, Loss_grad = 24.2429, L2 = 0.1193, Dot = 0.0108, Cosine = 0.3910
[Epoch 1 | Batch 064 | Step 00] Loss_cls = 1.5389, Loss_grad = 62.0000, L2 = 0.1704, Dot = 0.0226, Cosine = 1.0000
[Epoch 1 | Batch 064 | Step 01] Loss_cls = 1.4727, Loss_grad = 61.9906, L2 = 0.1501, Dot = 0.0144, Cosine = 0.9998
[Epoch 1 | Batch 064 | Step 02] Loss_cls = 1.5534, Loss_grad = 52.3626, L2 = 0.1331, Dot = 0.0102, Cosine = 0.8446
[Epoch 1 | Batch 064 | Step 03] Loss_cls = 1.6179, Loss_grad = 36.1601, L2 = 0.1282, Dot = 0.0104, Cosine = 0.5832
[Epoch 1 | Batch 064 | Step 04] Loss_cls = 1.6425, Loss_grad = 14.6596, L2 = 0.1125, Dot = 0.0075, Cosine = 0.2364
[Epoch 1 | Batch 065 | Step 00] Loss_cls = 1.5052, Loss_grad = 62.0000, L2 = 0.1328, Dot = 0.0131, Cosine = 1.0000
[Epoch 1 | Batch 065 | Step 01] Loss_cls = 1.4883, Loss_grad = 61.9929, L2 = 0.1269, Dot = 0.0107, Cosine = 0.9999
[Epoch 1 | Batch 065 | Step 02] Loss_cls = 1.4170, Loss_grad = 57.4919, L2 = 0.1195, Dot = 0.0093, Cosine = 0.9273
[Epoch 1 | Batch 065 | Step 03] Loss_cls = 1.3715, Loss_grad = 45.6656, L2 = 0.1112, Dot = 0.0082, Cosine = 0.7365
[Epoch 1 | Batch 065 | Step 04] Loss_cls = 1.3380, Loss_grad = 25.9698, L2 = 0.0997, Dot = 0.0060, Cosine = 0.4189
[Epoch 1 | Batch 066 | Step 00] Loss_cls = 1.3426, Loss_grad = 62.0000, L2 = 0.1222, Dot = 0.0107, Cosine = 1.0000
[Epoch 1 | Batch 066 | Step 01] Loss_cls = 1.3194, Loss_grad = 61.9911, L2 = 0.1246, Dot = 0.0109, Cosine = 0.9999
[Epoch 1 | Batch 066 | Step 02] Loss_cls = 1.1991, Loss_grad = 52.4326, L2 = 0.1112, Dot = 0.0075, Cosine = 0.8457
[Epoch 1 | Batch 066 | Step 03] Loss_cls = 1.1504, Loss_grad = 37.5364, L2 = 0.0972, Dot = 0.0048, Cosine = 0.6054
[Epoch 1 | Batch 066 | Step 04] Loss_cls = 1.1308, Loss_grad = 14.0207, L2 = 0.0875, Dot = 0.0026, Cosine = 0.2261
[Epoch 1 | Batch 067 | Step 00] Loss_cls = 1.3690, Loss_grad = 62.0000, L2 = 0.1735, Dot = 0.0186, Cosine = 1.0000
[Epoch 1 | Batch 067 | Step 01] Loss_cls = 1.3212, Loss_grad = 61.9352, L2 = 0.1517, Dot = 0.0141, Cosine = 0.9990
[Epoch 1 | Batch 067 | Step 02] Loss_cls = 1.2114, Loss_grad = 49.2397, L2 = 0.1142, Dot = 0.0072, Cosine = 0.7942
[Epoch 1 | Batch 067 | Step 03] Loss_cls = 1.1375, Loss_grad = 31.1808, L2 = 0.1010, Dot = 0.0048, Cosine = 0.5029
[Epoch 1 | Batch 067 | Step 04] Loss_cls = 1.1042, Loss_grad = 3.0177, L2 = 0.0959, Dot = 0.0024, Cosine = 0.0487
[Epoch 1 | Batch 068 | Step 00] Loss_cls = 1.3235, Loss_grad = 62.0000, L2 = 0.1769, Dot = 0.0194, Cosine = 1.0000
[Epoch 1 | Batch 068 | Step 01] Loss_cls = 1.2896, Loss_grad = 61.9748, L2 = 0.1615, Dot = 0.0156, Cosine = 0.9996
[Epoch 1 | Batch 068 | Step 02] Loss_cls = 1.4094, Loss_grad = 47.7760, L2 = 0.1391, Dot = 0.0090, Cosine = 0.7706
[Epoch 1 | Batch 068 | Step 03] Loss_cls = 1.4810, Loss_grad = 18.8613, L2 = 0.1140, Dot = 0.0034, Cosine = 0.3042
[Epoch 1 | Batch 068 | Step 04] Loss_cls = 1.5473, Loss_grad = 3.7097, L2 = 0.1156, Dot = 0.0026, Cosine = 0.0598
[Epoch 1 | Batch 069 | Step 00] Loss_cls = 1.4361, Loss_grad = 62.0000, L2 = 0.1866, Dot = 0.0219, Cosine = 1.0000
[Epoch 1 | Batch 069 | Step 01] Loss_cls = 1.3860, Loss_grad = 61.9927, L2 = 0.1663, Dot = 0.0167, Cosine = 0.9999
[Epoch 1 | Batch 069 | Step 02] Loss_cls = 1.2984, Loss_grad = 53.7890, L2 = 0.1215, Dot = 0.0079, Cosine = 0.8676
[Epoch 1 | Batch 069 | Step 03] Loss_cls = 1.3118, Loss_grad = 34.3709, L2 = 0.0979, Dot = 0.0042, Cosine = 0.5544
[Epoch 1 | Batch 069 | Step 04] Loss_cls = 1.4020, Loss_grad = 22.3886, L2 = 0.1139, Dot = 0.0070, Cosine = 0.3611
[Epoch 1 | Batch 070 | Step 00] Loss_cls = 1.3168, Loss_grad = 62.0000, L2 = 0.1309, Dot = 0.0108, Cosine = 1.0000
[Epoch 1 | Batch 070 | Step 01] Loss_cls = 1.3051, Loss_grad = 61.9920, L2 = 0.1207, Dot = 0.0087, Cosine = 0.9999
[Epoch 1 | Batch 070 | Step 02] Loss_cls = 1.3052, Loss_grad = 53.2889, L2 = 0.1052, Dot = 0.0059, Cosine = 0.8595
[Epoch 1 | Batch 070 | Step 03] Loss_cls = 1.3377, Loss_grad = 31.6829, L2 = 0.0932, Dot = 0.0036, Cosine = 0.5110
[Epoch 1 | Batch 070 | Step 04] Loss_cls = 1.3944, Loss_grad = 3.2908, L2 = 0.0857, Dot = 0.0013, Cosine = 0.0531
[Epoch 1 | Batch 071 | Step 00] Loss_cls = 1.2566, Loss_grad = 62.0000, L2 = 0.1307, Dot = 0.0101, Cosine = 1.0000
[Epoch 1 | Batch 071 | Step 01] Loss_cls = 1.2733, Loss_grad = 61.9921, L2 = 0.1436, Dot = 0.0121, Cosine = 0.9999
[Epoch 1 | Batch 071 | Step 02] Loss_cls = 1.3003, Loss_grad = 57.1816, L2 = 0.1336, Dot = 0.0098, Cosine = 0.9223
[Epoch 1 | Batch 071 | Step 03] Loss_cls = 1.3075, Loss_grad = 42.8547, L2 = 0.1065, Dot = 0.0053, Cosine = 0.6912
[Epoch 1 | Batch 071 | Step 04] Loss_cls = 1.3248, Loss_grad = 16.9647, L2 = 0.0860, Dot = 0.0022, Cosine = 0.2736
[Epoch 1 | Batch 072 | Step 00] Loss_cls = 1.4272, Loss_grad = 62.0000, L2 = 0.1403, Dot = 0.0127, Cosine = 1.0000
[Epoch 1 | Batch 072 | Step 01] Loss_cls = 1.4070, Loss_grad = 61.9922, L2 = 0.1347, Dot = 0.0115, Cosine = 0.9999
[Epoch 1 | Batch 072 | Step 02] Loss_cls = 1.4465, Loss_grad = 52.3685, L2 = 0.1209, Dot = 0.0084, Cosine = 0.8447
[Epoch 1 | Batch 072 | Step 03] Loss_cls = 1.4772, Loss_grad = 30.0623, L2 = 0.1043, Dot = 0.0051, Cosine = 0.4849
[Epoch 1 | Batch 072 | Step 04] Loss_cls = 1.5320, Loss_grad = 6.9056, L2 = 0.0967, Dot = 0.0029, Cosine = 0.1114
[Epoch 1 | Batch 073 | Step 00] Loss_cls = 1.4109, Loss_grad = 62.0000, L2 = 0.1284, Dot = 0.0095, Cosine = 1.0000
[Epoch 1 | Batch 073 | Step 01] Loss_cls = 1.4185, Loss_grad = 61.9918, L2 = 0.1280, Dot = 0.0092, Cosine = 0.9999
[Epoch 1 | Batch 073 | Step 02] Loss_cls = 1.5065, Loss_grad = 55.9428, L2 = 0.1298, Dot = 0.0088, Cosine = 0.9023
[Epoch 1 | Batch 073 | Step 03] Loss_cls = 1.5478, Loss_grad = 37.5176, L2 = 0.1122, Dot = 0.0053, Cosine = 0.6051
[Epoch 1 | Batch 073 | Step 04] Loss_cls = 1.5634, Loss_grad = 7.2863, L2 = 0.0867, Dot = 0.0016, Cosine = 0.1175
[Epoch 1 | Batch 074 | Step 00] Loss_cls = 1.4374, Loss_grad = 62.0000, L2 = 0.1172, Dot = 0.0084, Cosine = 1.0000
[Epoch 1 | Batch 074 | Step 01] Loss_cls = 1.4268, Loss_grad = 61.9918, L2 = 0.1145, Dot = 0.0077, Cosine = 0.9999
[Epoch 1 | Batch 074 | Step 02] Loss_cls = 1.3519, Loss_grad = 57.6065, L2 = 0.1055, Dot = 0.0060, Cosine = 0.9291
[Epoch 1 | Batch 074 | Step 03] Loss_cls = 1.3186, Loss_grad = 50.0911, L2 = 0.0989, Dot = 0.0047, Cosine = 0.8079
[Epoch 1 | Batch 074 | Step 04] Loss_cls = 1.3065, Loss_grad = 39.4519, L2 = 0.0980, Dot = 0.0040, Cosine = 0.6363
[Epoch 1 | Batch 075 | Step 00] Loss_cls = 1.3356, Loss_grad = 62.0000, L2 = 0.1281, Dot = 0.0094, Cosine = 1.0000
[Epoch 1 | Batch 075 | Step 01] Loss_cls = 1.2885, Loss_grad = 61.9951, L2 = 0.1259, Dot = 0.0094, Cosine = 0.9999
[Epoch 1 | Batch 075 | Step 02] Loss_cls = 1.2897, Loss_grad = 52.4271, L2 = 0.1146, Dot = 0.0073, Cosine = 0.8456
[Epoch 1 | Batch 075 | Step 03] Loss_cls = 1.3197, Loss_grad = 28.2570, L2 = 0.0972, Dot = 0.0035, Cosine = 0.4558
[Epoch 1 | Batch 075 | Step 04] Loss_cls = 1.3826, Loss_grad = 2.7642, L2 = 0.0911, Dot = 0.0014, Cosine = 0.0446
[Epoch 1 | Batch 076 | Step 00] Loss_cls = 1.3225, Loss_grad = 62.0000, L2 = 0.1295, Dot = 0.0129, Cosine = 1.0000
[Epoch 1 | Batch 076 | Step 01] Loss_cls = 1.3161, Loss_grad = 61.9897, L2 = 0.1316, Dot = 0.0127, Cosine = 0.9998
[Epoch 1 | Batch 076 | Step 02] Loss_cls = 1.2899, Loss_grad = 53.7417, L2 = 0.1256, Dot = 0.0100, Cosine = 0.8668
[Epoch 1 | Batch 076 | Step 03] Loss_cls = 1.2570, Loss_grad = 32.2475, L2 = 0.1111, Dot = 0.0061, Cosine = 0.5201
[Epoch 1 | Batch 076 | Step 04] Loss_cls = 1.2588, Loss_grad = 0.7173, L2 = 0.0990, Dot = 0.0022, Cosine = 0.0116
[Epoch 1 | Batch 077 | Step 00] Loss_cls = 1.4747, Loss_grad = 62.0000, L2 = 0.1989, Dot = 0.0237, Cosine = 1.0000
[Epoch 1 | Batch 077 | Step 01] Loss_cls = 1.4619, Loss_grad = 61.9969, L2 = 0.2012, Dot = 0.0245, Cosine = 0.9999
[Epoch 1 | Batch 077 | Step 02] Loss_cls = 1.3573, Loss_grad = 56.5531, L2 = 0.1615, Dot = 0.0155, Cosine = 0.9121
[Epoch 1 | Batch 077 | Step 03] Loss_cls = 1.2951, Loss_grad = 36.1765, L2 = 0.1063, Dot = 0.0056, Cosine = 0.5835
[Epoch 1 | Batch 077 | Step 04] Loss_cls = 1.3297, Loss_grad = 11.8905, L2 = 0.0877, Dot = 0.0022, Cosine = 0.1918
[Epoch 1 | Batch 078 | Step 00] Loss_cls = 1.3358, Loss_grad = 62.0000, L2 = 0.1552, Dot = 0.0149, Cosine = 1.0000
[Epoch 1 | Batch 078 | Step 01] Loss_cls = 1.3525, Loss_grad = 61.9952, L2 = 0.1584, Dot = 0.0153, Cosine = 0.9999
[Epoch 1 | Batch 078 | Step 02] Loss_cls = 1.3060, Loss_grad = 56.5786, L2 = 0.1368, Dot = 0.0107, Cosine = 0.9126
[Epoch 1 | Batch 078 | Step 03] Loss_cls = 1.3068, Loss_grad = 39.3249, L2 = 0.1076, Dot = 0.0055, Cosine = 0.6343
[Epoch 1 | Batch 078 | Step 04] Loss_cls = 1.3572, Loss_grad = 14.7180, L2 = 0.0957, Dot = 0.0029, Cosine = 0.2374
[Epoch 1 | Batch 079 | Step 00] Loss_cls = 1.3679, Loss_grad = 62.0000, L2 = 0.1329, Dot = 0.0113, Cosine = 1.0000
[Epoch 1 | Batch 079 | Step 01] Loss_cls = 1.3663, Loss_grad = 61.9924, L2 = 0.1348, Dot = 0.0112, Cosine = 0.9999
[Epoch 1 | Batch 079 | Step 02] Loss_cls = 1.3430, Loss_grad = 54.2320, L2 = 0.1303, Dot = 0.0096, Cosine = 0.8747
[Epoch 1 | Batch 079 | Step 03] Loss_cls = 1.3502, Loss_grad = 36.6947, L2 = 0.1148, Dot = 0.0064, Cosine = 0.5918
[Epoch 1 | Batch 079 | Step 04] Loss_cls = 1.3769, Loss_grad = 9.5220, L2 = 0.0981, Dot = 0.0029, Cosine = 0.1536
[Epoch 1 | Batch 080 | Step 00] Loss_cls = 1.3437, Loss_grad = 62.0000, L2 = 0.1330, Dot = 0.0117, Cosine = 1.0000
[Epoch 1 | Batch 080 | Step 01] Loss_cls = 1.3378, Loss_grad = 61.9910, L2 = 0.1324, Dot = 0.0111, Cosine = 0.9999
[Epoch 1 | Batch 080 | Step 02] Loss_cls = 1.2896, Loss_grad = 56.1902, L2 = 0.1295, Dot = 0.0093, Cosine = 0.9063
[Epoch 1 | Batch 080 | Step 03] Loss_cls = 1.2578, Loss_grad = 44.7507, L2 = 0.1258, Dot = 0.0077, Cosine = 0.7218
[Epoch 1 | Batch 080 | Step 04] Loss_cls = 1.2532, Loss_grad = 23.4866, L2 = 0.1189, Dot = 0.0053, Cosine = 0.3788
[Epoch 1 | Batch 081 | Step 00] Loss_cls = 1.3045, Loss_grad = 62.0000, L2 = 0.1330, Dot = 0.0103, Cosine = 1.0000
[Epoch 1 | Batch 081 | Step 01] Loss_cls = 1.2883, Loss_grad = 61.9892, L2 = 0.1358, Dot = 0.0102, Cosine = 0.9998
[Epoch 1 | Batch 081 | Step 02] Loss_cls = 1.4621, Loss_grad = 48.9542, L2 = 0.1451, Dot = 0.0102, Cosine = 0.7896
[Epoch 1 | Batch 081 | Step 03] Loss_cls = 1.5428, Loss_grad = 25.4372, L2 = 0.1420, Dot = 0.0062, Cosine = 0.4103
[Epoch 1 | Batch 081 | Step 04] Loss_cls = 1.5286, Loss_grad = 3.1863, L2 = 0.1084, Dot = 0.0018, Cosine = 0.0514
[Epoch 1 | Batch 082 | Step 00] Loss_cls = 1.2276, Loss_grad = 62.0000, L2 = 0.1152, Dot = 0.0084, Cosine = 1.0000
[Epoch 1 | Batch 082 | Step 01] Loss_cls = 1.2218, Loss_grad = 61.9930, L2 = 0.1079, Dot = 0.0070, Cosine = 0.9999
[Epoch 1 | Batch 082 | Step 02] Loss_cls = 1.1515, Loss_grad = 56.8149, L2 = 0.1060, Dot = 0.0059, Cosine = 0.9164
[Epoch 1 | Batch 082 | Step 03] Loss_cls = 1.1225, Loss_grad = 47.1945, L2 = 0.0991, Dot = 0.0045, Cosine = 0.7612
[Epoch 1 | Batch 082 | Step 04] Loss_cls = 1.1065, Loss_grad = 29.0786, L2 = 0.0902, Dot = 0.0029, Cosine = 0.4690
[Epoch 1 | Batch 083 | Step 00] Loss_cls = 1.3751, Loss_grad = 62.0000, L2 = 0.1158, Dot = 0.0076, Cosine = 1.0000
[Epoch 1 | Batch 083 | Step 01] Loss_cls = 1.3702, Loss_grad = 61.9910, L2 = 0.1200, Dot = 0.0083, Cosine = 0.9999
[Epoch 1 | Batch 083 | Step 02] Loss_cls = 1.2876, Loss_grad = 53.2452, L2 = 0.1226, Dot = 0.0081, Cosine = 0.8588
[Epoch 1 | Batch 083 | Step 03] Loss_cls = 1.2359, Loss_grad = 31.5407, L2 = 0.1085, Dot = 0.0051, Cosine = 0.5087
[Epoch 1 | Batch 083 | Step 04] Loss_cls = 1.2000, Loss_grad = -5.2428, L2 = 0.0830, Dot = 0.0004, Cosine = -0.0846
[Epoch 1 | Batch 084 | Step 00] Loss_cls = 1.3279, Loss_grad = 62.0000, L2 = 0.1546, Dot = 0.0132, Cosine = 1.0000
[Epoch 1 | Batch 084 | Step 01] Loss_cls = 1.3616, Loss_grad = 61.9977, L2 = 0.1706, Dot = 0.0159, Cosine = 1.0000
[Epoch 1 | Batch 084 | Step 02] Loss_cls = 1.2975, Loss_grad = 57.0139, L2 = 0.1561, Dot = 0.0128, Cosine = 0.9196
[Epoch 1 | Batch 084 | Step 03] Loss_cls = 1.2836, Loss_grad = 44.7167, L2 = 0.1355, Dot = 0.0088, Cosine = 0.7212
[Epoch 1 | Batch 084 | Step 04] Loss_cls = 1.2947, Loss_grad = 25.4747, L2 = 0.1176, Dot = 0.0051, Cosine = 0.4109
[Epoch 1 | Batch 085 | Step 00] Loss_cls = 1.1618, Loss_grad = 62.0000, L2 = 0.1043, Dot = 0.0062, Cosine = 1.0000
[Epoch 1 | Batch 085 | Step 01] Loss_cls = 1.1552, Loss_grad = 61.9885, L2 = 0.1107, Dot = 0.0067, Cosine = 0.9998
[Epoch 1 | Batch 085 | Step 02] Loss_cls = 1.1734, Loss_grad = 52.1996, L2 = 0.1150, Dot = 0.0066, Cosine = 0.8419
[Epoch 1 | Batch 085 | Step 03] Loss_cls = 1.1805, Loss_grad = 32.6841, L2 = 0.1119, Dot = 0.0050, Cosine = 0.5272
[Epoch 1 | Batch 085 | Step 04] Loss_cls = 1.2008, Loss_grad = 6.0686, L2 = 0.1012, Dot = 0.0018, Cosine = 0.0979
[Epoch 1 | Batch 086 | Step 00] Loss_cls = 1.3693, Loss_grad = 62.0000, L2 = 0.1761, Dot = 0.0177, Cosine = 1.0000
[Epoch 1 | Batch 086 | Step 01] Loss_cls = 1.3068, Loss_grad = 61.9941, L2 = 0.1559, Dot = 0.0138, Cosine = 0.9999
[Epoch 1 | Batch 086 | Step 02] Loss_cls = 1.3706, Loss_grad = 48.9232, L2 = 0.1281, Dot = 0.0085, Cosine = 0.7891
[Epoch 1 | Batch 086 | Step 03] Loss_cls = 1.4098, Loss_grad = 23.9132, L2 = 0.0980, Dot = 0.0032, Cosine = 0.3857
[Epoch 1 | Batch 086 | Step 04] Loss_cls = 1.4692, Loss_grad = -4.5005, L2 = 0.0814, Dot = 0.0006, Cosine = -0.0726
[Epoch 1 | Batch 087 | Step 00] Loss_cls = 1.2802, Loss_grad = 62.0000, L2 = 0.1399, Dot = 0.0114, Cosine = 1.0000
[Epoch 1 | Batch 087 | Step 01] Loss_cls = 1.3011, Loss_grad = 61.9938, L2 = 0.1370, Dot = 0.0109, Cosine = 0.9999
[Epoch 1 | Batch 087 | Step 02] Loss_cls = 1.3369, Loss_grad = 56.3423, L2 = 0.1248, Dot = 0.0084, Cosine = 0.9087
[Epoch 1 | Batch 087 | Step 03] Loss_cls = 1.3621, Loss_grad = 42.9454, L2 = 0.1104, Dot = 0.0059, Cosine = 0.6927
[Epoch 1 | Batch 087 | Step 04] Loss_cls = 1.3925, Loss_grad = 20.0828, L2 = 0.0987, Dot = 0.0035, Cosine = 0.3239
[Epoch 1 | Batch 088 | Step 00] Loss_cls = 1.3320, Loss_grad = 62.0000, L2 = 0.1260, Dot = 0.0093, Cosine = 1.0000
[Epoch 1 | Batch 088 | Step 01] Loss_cls = 1.3075, Loss_grad = 61.9962, L2 = 0.1345, Dot = 0.0103, Cosine = 0.9999
[Epoch 1 | Batch 088 | Step 02] Loss_cls = 1.2742, Loss_grad = 56.7576, L2 = 0.1186, Dot = 0.0076, Cosine = 0.9154
[Epoch 1 | Batch 088 | Step 03] Loss_cls = 1.2468, Loss_grad = 40.4458, L2 = 0.0952, Dot = 0.0041, Cosine = 0.6524
[Epoch 1 | Batch 088 | Step 04] Loss_cls = 1.2763, Loss_grad = 15.1592, L2 = 0.0790, Dot = 0.0016, Cosine = 0.2445
[Epoch 1 | Batch 089 | Step 00] Loss_cls = 1.2648, Loss_grad = 62.0000, L2 = 0.1373, Dot = 0.0111, Cosine = 1.0000
[Epoch 1 | Batch 089 | Step 01] Loss_cls = 1.2384, Loss_grad = 61.9947, L2 = 0.1312, Dot = 0.0104, Cosine = 0.9999
[Epoch 1 | Batch 089 | Step 02] Loss_cls = 1.1656, Loss_grad = 54.9868, L2 = 0.1192, Dot = 0.0083, Cosine = 0.8869
[Epoch 1 | Batch 089 | Step 03] Loss_cls = 1.1298, Loss_grad = 33.7515, L2 = 0.1004, Dot = 0.0047, Cosine = 0.5444
[Epoch 1 | Batch 089 | Step 04] Loss_cls = 1.1473, Loss_grad = 3.1514, L2 = 0.0854, Dot = 0.0013, Cosine = 0.0508
[Epoch 1 | Batch 090 | Step 00] Loss_cls = 1.2820, Loss_grad = 62.0000, L2 = 0.1242, Dot = 0.0100, Cosine = 1.0000
[Epoch 1 | Batch 090 | Step 01] Loss_cls = 1.2857, Loss_grad = 61.9834, L2 = 0.1260, Dot = 0.0100, Cosine = 0.9997
[Epoch 1 | Batch 090 | Step 02] Loss_cls = 1.3682, Loss_grad = 48.2685, L2 = 0.1191, Dot = 0.0078, Cosine = 0.7785
[Epoch 1 | Batch 090 | Step 03] Loss_cls = 1.3762, Loss_grad = 26.5773, L2 = 0.1004, Dot = 0.0042, Cosine = 0.4287
[Epoch 1 | Batch 090 | Step 04] Loss_cls = 1.3929, Loss_grad = 6.6505, L2 = 0.0880, Dot = 0.0020, Cosine = 0.1073
[Epoch 1 | Batch 091 | Step 00] Loss_cls = 1.3818, Loss_grad = 62.0000, L2 = 0.1522, Dot = 0.0133, Cosine = 1.0000
[Epoch 1 | Batch 091 | Step 01] Loss_cls = 1.3365, Loss_grad = 61.9955, L2 = 0.1386, Dot = 0.0109, Cosine = 0.9999
[Epoch 1 | Batch 091 | Step 02] Loss_cls = 1.1925, Loss_grad = 55.8795, L2 = 0.1120, Dot = 0.0069, Cosine = 0.9013
[Epoch 1 | Batch 091 | Step 03] Loss_cls = 1.1215, Loss_grad = 41.3903, L2 = 0.0916, Dot = 0.0038, Cosine = 0.6676
[Epoch 1 | Batch 091 | Step 04] Loss_cls = 1.1010, Loss_grad = 18.4959, L2 = 0.0799, Dot = 0.0017, Cosine = 0.2983
[Epoch 1 | Batch 092 | Step 00] Loss_cls = 1.1815, Loss_grad = 62.0000, L2 = 0.1062, Dot = 0.0064, Cosine = 1.0000
[Epoch 1 | Batch 092 | Step 01] Loss_cls = 1.1768, Loss_grad = 61.9917, L2 = 0.1122, Dot = 0.0075, Cosine = 0.9999
[Epoch 1 | Batch 092 | Step 02] Loss_cls = 1.1458, Loss_grad = 55.3633, L2 = 0.1079, Dot = 0.0067, Cosine = 0.8930
[Epoch 1 | Batch 092 | Step 03] Loss_cls = 1.0880, Loss_grad = 39.5311, L2 = 0.0936, Dot = 0.0042, Cosine = 0.6376
[Epoch 1 | Batch 092 | Step 04] Loss_cls = 1.0697, Loss_grad = 14.5061, L2 = 0.0805, Dot = 0.0019, Cosine = 0.2340
[Epoch 1 | Batch 093 | Step 00] Loss_cls = 1.3322, Loss_grad = 62.0000, L2 = 0.1239, Dot = 0.0092, Cosine = 1.0000
[Epoch 1 | Batch 093 | Step 01] Loss_cls = 1.3110, Loss_grad = 61.9908, L2 = 0.1231, Dot = 0.0091, Cosine = 0.9999
[Epoch 1 | Batch 093 | Step 02] Loss_cls = 1.1902, Loss_grad = 49.5826, L2 = 0.1072, Dot = 0.0066, Cosine = 0.7997
[Epoch 1 | Batch 093 | Step 03] Loss_cls = 1.1752, Loss_grad = 29.0148, L2 = 0.0961, Dot = 0.0042, Cosine = 0.4680
[Epoch 1 | Batch 093 | Step 04] Loss_cls = 1.1881, Loss_grad = 4.2272, L2 = 0.0887, Dot = 0.0015, Cosine = 0.0682
[Epoch 1 | Batch 094 | Step 00] Loss_cls = 1.1381, Loss_grad = 62.0000, L2 = 0.1055, Dot = 0.0061, Cosine = 1.0000
[Epoch 1 | Batch 094 | Step 01] Loss_cls = 1.1423, Loss_grad = 61.9903, L2 = 0.1207, Dot = 0.0080, Cosine = 0.9998
[Epoch 1 | Batch 094 | Step 02] Loss_cls = 1.2464, Loss_grad = 51.0193, L2 = 0.1363, Dot = 0.0093, Cosine = 0.8229
[Epoch 1 | Batch 094 | Step 03] Loss_cls = 1.3193, Loss_grad = 26.0745, L2 = 0.1230, Dot = 0.0053, Cosine = 0.4206
[Epoch 1 | Batch 094 | Step 04] Loss_cls = 1.3751, Loss_grad = -13.1421, L2 = 0.0965, Dot = -0.0008, Cosine = -0.2120
[Epoch 1 | Batch 095 | Step 00] Loss_cls = 1.1524, Loss_grad = 62.0000, L2 = 0.1283, Dot = 0.0088, Cosine = 1.0000
[Epoch 1 | Batch 095 | Step 01] Loss_cls = 1.1620, Loss_grad = 61.9891, L2 = 0.1333, Dot = 0.0094, Cosine = 0.9998
[Epoch 1 | Batch 095 | Step 02] Loss_cls = 1.1962, Loss_grad = 52.8292, L2 = 0.1330, Dot = 0.0086, Cosine = 0.8521
[Epoch 1 | Batch 095 | Step 03] Loss_cls = 1.2378, Loss_grad = 31.3503, L2 = 0.1179, Dot = 0.0052, Cosine = 0.5057
[Epoch 1 | Batch 095 | Step 04] Loss_cls = 1.2783, Loss_grad = 3.6783, L2 = 0.0985, Dot = 0.0013, Cosine = 0.0593
[Epoch 1 | Batch 096 | Step 00] Loss_cls = 1.1748, Loss_grad = 62.0000, L2 = 0.1089, Dot = 0.0062, Cosine = 1.0000
[Epoch 1 | Batch 096 | Step 01] Loss_cls = 1.1888, Loss_grad = 61.9918, L2 = 0.1186, Dot = 0.0074, Cosine = 0.9999
[Epoch 1 | Batch 096 | Step 02] Loss_cls = 1.1769, Loss_grad = 55.1822, L2 = 0.1192, Dot = 0.0071, Cosine = 0.8900
[Epoch 1 | Batch 096 | Step 03] Loss_cls = 1.1603, Loss_grad = 35.8263, L2 = 0.1006, Dot = 0.0041, Cosine = 0.5778
[Epoch 1 | Batch 096 | Step 04] Loss_cls = 1.1476, Loss_grad = 4.4261, L2 = 0.0809, Dot = 0.0010, Cosine = 0.0714
[Epoch 1 | Batch 097 | Step 00] Loss_cls = 1.3002, Loss_grad = 62.0000, L2 = 0.1332, Dot = 0.0097, Cosine = 1.0000
[Epoch 1 | Batch 097 | Step 01] Loss_cls = 1.2885, Loss_grad = 61.9906, L2 = 0.1326, Dot = 0.0097, Cosine = 0.9998
[Epoch 1 | Batch 097 | Step 02] Loss_cls = 1.3140, Loss_grad = 52.8411, L2 = 0.1218, Dot = 0.0076, Cosine = 0.8523
[Epoch 1 | Batch 097 | Step 03] Loss_cls = 1.3680, Loss_grad = 28.1561, L2 = 0.1039, Dot = 0.0040, Cosine = 0.4541
[Epoch 1 | Batch 097 | Step 04] Loss_cls = 1.4190, Loss_grad = -0.2587, L2 = 0.0889, Dot = 0.0008, Cosine = -0.0042
Epoch [1] Test Acc: 49.04% 
✅ Saved perturbed x2 for epoch 1.
